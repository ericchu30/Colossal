\clearpage
%\appendix
\section{Demonstration Proposal}

\subsection{Colossal-based solutions}
Overall, Colossal supports 1) simulating the performance of the
cluster under given workload and configuration, 2) modeling the
workload and allowing for modifications, and 3) automatic parameter
tuning based on given performance metrics. Specifically, 1) is
achieved using the pluggable scheduler simulator in Colossal, 2) is
done by fitting a statistical model to historical workload traces,
and 3) relies on 1) to perform exhaustive or heuristic search over
the parameter space.

As a proof-of-concept, we have implemented a prototype of ...

We will first describe the design of the prototype system.
Then, we describe how we will demonstrate the 
prototype system to motivate and illustrate the ...

\vspace{-1mm}
\subsection{Description of Prototype System}


Colossal is designed to answer ``What-If'' questions concerning the
cluster performance, workload, and parameters. The general steps to
pose a ``What-If'' question are shown in Fig 5. First, workload is
either extracted from Hadoop job history or generated using the
workload model. Second, the simulator inputs the workload and
cluster configurations, and then outputs a performance metrics
file, which is similar to Hadoop metrics, as well as the schedule.

\subsubsection{Posing a question in Colossal}
To pose performance related questions, one simply needs to
visualize the metrics time series in the metric file, or
alternatively to analyze the schedule. Colossal provides several
built-in performance metrics, such as effective utilization as
described in the previous section and the average job latency for
each pool. To pose questions concerning the workload, the
statistical workload model introduced in 3.1 is readily available
for modifications. As for automatic parameter tuning, one can fix
the objective, e.g., average job latency of analyst pool, and then
repeat the simulation against different parameter combinations. In
this case, constraints can also be specified by the user in a
similar manner. This is useful to guarantee the SLAs of production
jobs.




Figure~\ref{} shows the architectural overview of the 

Specifically, there are two components that we have developed: 

\vspace{1mm}
\noindent\textbf{TBD:}

\vspace{1mm}
\noindent\textbf{TBD:} 

\vspace{-1mm}
\subsection{Outline of Demonstration Plan}
The demonstration will consist of three parts. First, we will show how to ..

Second, we will also show how 

Finally, we will show the 


\begin{table*}
  \centering
  \caption{Procedures to pose questions in Colossal}
  \begin{tabular}{|p{6cm}|p{10cm}|l|} \hline
    Question&Procedures\\ \hline
    What is the effective utilization of the cluster?& Use the
    simulator to generate the schedule files. Then use built-in
    function EffUtil(S) to obtain the effective utilization based on
    S.\\ \hline
    What is the impact of a change in workload?& Reflect the change in
    the workload model, and then run Colossal to generate metrics and
    schedule files. Next, compute the performance metrics of interest
    based on these two files.\\ \hline
    Should preemptions be turned off?& First, visualize the metrics
    file generated by Colossal for the present workload. Then identify
    any long-running tasks problem in any pools. Next, compare the
    performance before and after turning off the preemptions. Finally,
    make a decision according to above results.\\ \hline
    How to evaluate the impact of a 5\% increase in the workload of
    analyst pool?& First, run Colossal to obtain baseline performance
    using any user-defined metrics. Then increase the job arrival rate
    of analyst pool by 5\% and re-evaluate the performance. Finally,
    compare the results above.\\ \hline
    How loosening the admission control of modeling pool impacts the
    performance?& Another module is needed to map the original
    workload to an adjusted one according to the loosened admission
    control. Then use Colossal to evaluate the performance using the
    adjusted workload.\\ \hline
    What difference does ORC format make? & Likewise, another module
    is needed to produce the adjusted workload and use Colossal to
    evaluate the performance of the adjusted workload.\\ \hline
  \end{tabular}
\end{table*}


The Colossal answers questions as
described in Section 2. These questions are first translated and then
effected on the workload model. The simulator processes the workload
generated by the workload model and outputs the schedule and
performance metrics for evaluation. 

Colossal is designed to answer ``What-If'' questions concerning the
cluster performance, workload, and parameters. The general steps to
pose a ``What-If'' question are shown in Fig 5. First, workload is
either extracted from Hadoop job history or generated using the
workload model. Second, the simulator inputs the workload and
cluster configurations, and then outputs a performance metrics
file, which is similar to Hadoop metrics, as well as the schedule.



As for automatic parameter tuning, one can fix
the objective, e.g., average job latency of analyst pool, and then
repeat the simulation against different parameter combinations. In
this case, constraints can also be specified by the user in a
similar manner. This is useful to guarantee the SLAs of production
jobs.


